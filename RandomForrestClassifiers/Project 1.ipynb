{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Sam Odle <br>\n",
    "Sept 22, 2021  <br>\n",
    "Project 1  <br>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 1: Dataset Download And Extraction\n",
    "*The dataset consists of feature vectors belonging to 12,330 sessions.\n",
    "The dataset was formed so that each session\n",
    "would belong to a different user in a 1-year period to avoid\n",
    "any tendency to a specific campaign, special day, user\n",
    "profile, or period.*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Load csv correctly into a DataFrame and show contents in a cell"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Administrative  Administrative_Duration  Informational  \\\n",
      "0               0                      0.0              0   \n",
      "1               0                      0.0              0   \n",
      "2               0                      0.0              0   \n",
      "3               0                      0.0              0   \n",
      "4               0                      0.0              0   \n",
      "\n",
      "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
      "0                     0.0             1.0                 0.000000   \n",
      "1                     0.0             2.0                64.000000   \n",
      "2                     0.0             1.0                 0.000000   \n",
      "3                     0.0             2.0                 2.666667   \n",
      "4                     0.0            10.0               627.500000   \n",
      "\n",
      "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
      "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
      "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
      "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
      "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
      "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
      "\n",
      "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
      "0        1       1            1  Returning_Visitor    False    False  \n",
      "1        2       1            2  Returning_Visitor    False    False  \n",
      "2        1       9            3  Returning_Visitor    False    False  \n",
      "3        2       2            4  Returning_Visitor    False    False  \n",
      "4        3       1            4  Returning_Visitor     True    False  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('online_shoppers_intention_cs4364.csv')\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Holdout dataset split as specified (use rows 10000 - 12331 as our holdout dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape = (10000, 18)\n",
      "Holdout Shape = (2330, 18)\n",
      "Initial Shape = (12330, 18)\n"
     ]
    }
   ],
   "source": [
    "df_holdout = df.iloc[10000:12331,]\n",
    "# print(df_holdout.head())\n",
    "\n",
    "df_train = df.drop(df.index[10000:12331])\n",
    "# print(df_train.head())\n",
    "\n",
    "print(f'Train Shape = {df_train.shape}')\n",
    "print(f'Holdout Shape = {df_holdout.shape}')\n",
    "print(f'Initial Shape = {df.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Correct explanation generalization from such a holdout split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Only taking the final 2330 rows as the holdout dataset is problematic for generalization as the dataset appears to be in (roughly) chronological order. This particular holdout set only includes records from November and December.  Retail can be heavily impacted by season trends meaning the holdout set is not representative of the records from other months."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 2: Data Cleaning\n",
    "##### Use value_counts() in pandas to print out the distributions of the categorical and ordinal numbered features (treat SpecialDay as categorical here). Turn on the setting to reveal missing data -- how many features, and what percent of them, were missing? Discuss in markdown in your notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26       1\n",
      "27       1\n",
      "20       2\n",
      "21       2\n",
      "23       3\n",
      "22       4\n",
      "24       4\n",
      "19       6\n",
      "18      12\n",
      "17      16\n",
      "16      24\n",
      "15      38\n",
      "14      44\n",
      "13      56\n",
      "12      86\n",
      "11     105\n",
      "10     153\n",
      "9      225\n",
      "8      287\n",
      "7      338\n",
      "6      432\n",
      "5      575\n",
      "4      765\n",
      "3      915\n",
      "2     1114\n",
      "1     1354\n",
      "0     5768\n",
      "Name: Administrative, dtype: int64\n",
      "\n",
      "\n",
      "(2973.906, 3398.75]         1\n",
      "(2124.219, 2549.062]        3\n",
      "(2549.062, 2973.906]        3\n",
      "(1699.375, 2124.219]        8\n",
      "(1274.531, 1699.375]       36\n",
      "(849.688, 1274.531]        69\n",
      "(424.844, 849.688]        321\n",
      "(-3.4, 424.844]         11889\n",
      "Name: Administrative_Duration, dtype: int64\n",
      "\n",
      "\n",
      "0     9699\n",
      "1     1041\n",
      "2      728\n",
      "3      380\n",
      "4      222\n",
      "5       99\n",
      "6       78\n",
      "7       36\n",
      "9       15\n",
      "8       14\n",
      "10       7\n",
      "12       5\n",
      "14       2\n",
      "16       1\n",
      "11       1\n",
      "24       1\n",
      "13       1\n",
      "Name: Informational, dtype: int64\n",
      "\n",
      "\n",
      "(2230.703, 2549.375]        3\n",
      "(1912.031, 2230.703]        4\n",
      "(1593.359, 1912.031]       10\n",
      "(1274.688, 1593.359]       16\n",
      "(956.016, 1274.688]        34\n",
      "(637.344, 956.016]         80\n",
      "(318.672, 637.344]        218\n",
      "(-2.55, 318.672]        11965\n",
      "Name: Informational_Duration, dtype: int64\n",
      "\n",
      "\n",
      "1.0      588\n",
      "2.0      443\n",
      "3.0      438\n",
      "4.0      383\n",
      "6.0      382\n",
      "7.0      379\n",
      "5.0      366\n",
      "8.0      360\n",
      "NaN      335\n",
      "10.0     321\n",
      "9.0      305\n",
      "12.0     305\n",
      "11.0     300\n",
      "13.0     284\n",
      "15.0     265\n",
      "16.0     252\n",
      "14.0     240\n",
      "17.0     220\n",
      "20.0     219\n",
      "19.0     213\n",
      "22.0     207\n",
      "21.0     196\n",
      "18.0     194\n",
      "24.0     190\n",
      "23.0     174\n",
      "27.0     174\n",
      "26.0     153\n",
      "25.0     153\n",
      "28.0     140\n",
      "30.0     140\n",
      "29.0     131\n",
      "31.0     126\n",
      "33.0     120\n",
      "32.0     116\n",
      "37.0     115\n",
      "39.0     108\n",
      "36.0     105\n",
      "34.0     102\n",
      "35.0      96\n",
      "38.0      88\n",
      "41.0      84\n",
      "42.0      75\n",
      "43.0      72\n",
      "40.0      69\n",
      "45.0      69\n",
      "44.0      69\n",
      "46.0      65\n",
      "48.0      62\n",
      "50.0      59\n",
      "49.0      59\n",
      "53.0      59\n",
      "47.0      55\n",
      "52.0      49\n",
      "51.0      49\n",
      "57.0      47\n",
      "59.0      47\n",
      "62.0      45\n",
      "54.0      45\n",
      "55.0      44\n",
      "56.0      42\n",
      "60.0      42\n",
      "58.0      41\n",
      "61.0      40\n",
      "66.0      38\n",
      "63.0      38\n",
      "0.0       38\n",
      "81.0      37\n",
      "64.0      36\n",
      "65.0      33\n",
      "71.0      32\n",
      "79.0      31\n",
      "68.0      30\n",
      "69.0      30\n",
      "67.0      29\n",
      "70.0      29\n",
      "85.0      28\n",
      "72.0      26\n",
      "74.0      25\n",
      "80.0      25\n",
      "77.0      24\n",
      "73.0      24\n",
      "82.0      23\n",
      "89.0      22\n",
      "83.0      21\n",
      "84.0      20\n",
      "93.0      20\n",
      "95.0      19\n",
      "76.0      18\n",
      "98.0      18\n",
      "91.0      18\n",
      "94.0      18\n",
      "75.0      17\n",
      "111.0     17\n",
      "90.0      16\n",
      "88.0      15\n",
      "97.0      15\n",
      "106.0     14\n",
      "86.0      14\n",
      "101.0     14\n",
      "87.0      14\n",
      "96.0      14\n",
      "107.0     13\n",
      "109.0     13\n",
      "108.0     13\n",
      "131.0     13\n",
      "122.0     12\n",
      "78.0      12\n",
      "103.0     12\n",
      "114.0     12\n",
      "113.0     12\n",
      "104.0     12\n",
      "154.0     11\n",
      "102.0     11\n",
      "115.0     11\n",
      "137.0     11\n",
      "130.0     10\n",
      "125.0     10\n",
      "129.0     10\n",
      "116.0     10\n",
      "100.0     10\n",
      "92.0      10\n",
      "118.0     10\n",
      "120.0      9\n",
      "99.0       9\n",
      "132.0      9\n",
      "110.0      9\n",
      "162.0      8\n",
      "133.0      8\n",
      "141.0      8\n",
      "152.0      8\n",
      "117.0      8\n",
      "112.0      7\n",
      "126.0      7\n",
      "149.0      7\n",
      "127.0      7\n",
      "140.0      7\n",
      "159.0      7\n",
      "171.0      7\n",
      "105.0      6\n",
      "146.0      6\n",
      "128.0      6\n",
      "124.0      6\n",
      "145.0      6\n",
      "150.0      6\n",
      "139.0      5\n",
      "155.0      5\n",
      "134.0      5\n",
      "119.0      5\n",
      "151.0      5\n",
      "157.0      5\n",
      "161.0      4\n",
      "121.0      4\n",
      "213.0      4\n",
      "200.0      4\n",
      "138.0      4\n",
      "222.0      4\n",
      "167.0      4\n",
      "164.0      4\n",
      "148.0      4\n",
      "143.0      4\n",
      "179.0      4\n",
      "176.0      4\n",
      "123.0      4\n",
      "136.0      4\n",
      "156.0      4\n",
      "172.0      4\n",
      "135.0      4\n",
      "195.0      3\n",
      "181.0      3\n",
      "153.0      3\n",
      "142.0      3\n",
      "229.0      3\n",
      "237.0      3\n",
      "147.0      3\n",
      "187.0      3\n",
      "230.0      3\n",
      "170.0      3\n",
      "202.0      3\n",
      "160.0      3\n",
      "186.0      3\n",
      "182.0      3\n",
      "193.0      3\n",
      "258.0      3\n",
      "189.0      3\n",
      "144.0      3\n",
      "227.0      3\n",
      "174.0      3\n",
      "178.0      3\n",
      "175.0      3\n",
      "221.0      3\n",
      "401.0      2\n",
      "231.0      2\n",
      "336.0      2\n",
      "166.0      2\n",
      "190.0      2\n",
      "264.0      2\n",
      "219.0      2\n",
      "197.0      2\n",
      "188.0      2\n",
      "238.0      2\n",
      "337.0      2\n",
      "245.0      2\n",
      "169.0      2\n",
      "224.0      2\n",
      "168.0      2\n",
      "199.0      2\n",
      "310.0      2\n",
      "198.0      2\n",
      "180.0      2\n",
      "206.0      2\n",
      "184.0      2\n",
      "204.0      2\n",
      "439.0      2\n",
      "220.0      2\n",
      "280.0      2\n",
      "173.0      2\n",
      "194.0      2\n",
      "216.0      2\n",
      "281.0      1\n",
      "312.0      1\n",
      "470.0      1\n",
      "534.0      1\n",
      "272.0      1\n",
      "338.0      1\n",
      "260.0      1\n",
      "266.0      1\n",
      "324.0      1\n",
      "226.0      1\n",
      "254.0      1\n",
      "218.0      1\n",
      "183.0      1\n",
      "313.0      1\n",
      "163.0      1\n",
      "359.0      1\n",
      "423.0      1\n",
      "349.0      1\n",
      "287.0      1\n",
      "351.0      1\n",
      "210.0      1\n",
      "207.0      1\n",
      "378.0      1\n",
      "279.0      1\n",
      "247.0      1\n",
      "248.0      1\n",
      "374.0      1\n",
      "283.0      1\n",
      "339.0      1\n",
      "328.0      1\n",
      "315.0      1\n",
      "234.0      1\n",
      "357.0      1\n",
      "286.0      1\n",
      "326.0      1\n",
      "330.0      1\n",
      "177.0      1\n",
      "261.0      1\n",
      "290.0      1\n",
      "276.0      1\n",
      "233.0      1\n",
      "205.0      1\n",
      "304.0      1\n",
      "211.0      1\n",
      "318.0      1\n",
      "343.0      1\n",
      "391.0      1\n",
      "223.0      1\n",
      "241.0      1\n",
      "243.0      1\n",
      "409.0      1\n",
      "262.0      1\n",
      "414.0      1\n",
      "377.0      1\n",
      "271.0      1\n",
      "246.0      1\n",
      "158.0      1\n",
      "486.0      1\n",
      "282.0      1\n",
      "191.0      1\n",
      "358.0      1\n",
      "255.0      1\n",
      "256.0      1\n",
      "518.0      1\n",
      "346.0      1\n",
      "686.0      1\n",
      "429.0      1\n",
      "274.0      1\n",
      "449.0      1\n",
      "305.0      1\n",
      "397.0      1\n",
      "705.0      1\n",
      "291.0      1\n",
      "240.0      1\n",
      "275.0      1\n",
      "217.0      1\n",
      "501.0      1\n",
      "235.0      1\n",
      "309.0      1\n",
      "225.0      1\n",
      "517.0      1\n",
      "251.0      1\n",
      "232.0      1\n",
      "292.0      1\n",
      "385.0      1\n",
      "362.0      1\n",
      "250.0      1\n",
      "340.0      1\n",
      "311.0      1\n",
      "440.0      1\n",
      "584.0      1\n",
      "293.0      1\n",
      "165.0      1\n",
      "192.0      1\n",
      "Name: ProductRelated, dtype: int64\n",
      "\n",
      "\n",
      "(31986.761, 39983.451]                0\n",
      "(47980.142, 55976.832]                0\n",
      "(39983.451, 47980.142]                1\n",
      "(55976.832, 63973.522]                1\n",
      "(23990.071, 31986.761]                3\n",
      "(15993.381, 23990.071]               11\n",
      "(7996.69, 15993.381]                145\n",
      "(-63.974999999999994, 7996.69]    12169\n",
      "Name: ProductRelated_Duration, dtype: int64\n",
      "\n",
      "\n",
      "(0.15, 0.175]                         14\n",
      "(0.125, 0.15]                         46\n",
      "(0.1, 0.125]                          49\n",
      "(0.075, 0.1]                         188\n",
      "(0.05, 0.075]                        312\n",
      "(0.175, 0.2]                         707\n",
      "(0.025, 0.05]                        966\n",
      "(-0.0012000000000000001, 0.025]    10048\n",
      "Name: BounceRates, dtype: int64\n",
      "\n",
      "\n",
      "(0.15, 0.175]                        62\n",
      "(0.1, 0.125]                        155\n",
      "(0.125, 0.15]                       166\n",
      "(0.075, 0.1]                        660\n",
      "(0.175, 0.2]                        729\n",
      "(0.05, 0.075]                      1047\n",
      "(0.025, 0.05]                      3366\n",
      "(-0.0012000000000000001, 0.025]    6145\n",
      "Name: ExitRates, dtype: int64\n",
      "\n",
      "\n",
      "(301.47, 361.764]         2\n",
      "(180.882, 241.176]        7\n",
      "(241.176, 301.47]         7\n",
      "(120.588, 180.882]       30\n",
      "(60.294, 120.588]       228\n",
      "(-0.363, 60.294]      12056\n",
      "Name: PageValues, dtype: int64\n",
      "\n",
      "\n",
      "1.0      154\n",
      "0.2      178\n",
      "0.4      243\n",
      "0.8      325\n",
      "0.6      351\n",
      "0.0    11079\n",
      "Name: SpecialDay, dtype: int64\n",
      "\n",
      "\n",
      "5       6\n",
      "7       7\n",
      "6      19\n",
      "8      79\n",
      "4     478\n",
      "3    2555\n",
      "1    2585\n",
      "2    6601\n",
      "Name: OperatingSystems, dtype: int64\n",
      "\n",
      "\n",
      "9        1\n",
      "11       6\n",
      "12      10\n",
      "7       49\n",
      "13      61\n",
      "3      105\n",
      "8      135\n",
      "10     163\n",
      "6      174\n",
      "5      467\n",
      "4      736\n",
      "1     2462\n",
      "2     7961\n",
      "Name: Browser, dtype: int64\n",
      "\n",
      "\n",
      "5     318\n",
      "8     434\n",
      "9     511\n",
      "7     761\n",
      "6     805\n",
      "2    1136\n",
      "4    1182\n",
      "3    2403\n",
      "1    4780\n",
      "Name: Region, dtype: int64\n",
      "\n",
      "\n",
      "17       1\n",
      "12       1\n",
      "16       3\n",
      "18      10\n",
      "14      13\n",
      "19      17\n",
      "15      38\n",
      "7       40\n",
      "9       42\n",
      "20     198\n",
      "11     247\n",
      "5      260\n",
      "8      343\n",
      "6      444\n",
      "10     450\n",
      "13     738\n",
      "4     1069\n",
      "3     2052\n",
      "1     2451\n",
      "2     3913\n",
      "Name: TrafficType, dtype: int64\n",
      "\n",
      "\n",
      "Feb      184\n",
      "June     288\n",
      "Jul      432\n",
      "Aug      433\n",
      "Sep      448\n",
      "Oct      549\n",
      "Dec     1727\n",
      "Mar     1907\n",
      "Nov     2998\n",
      "May     3364\n",
      "Name: Month, dtype: int64\n",
      "\n",
      "\n",
      "Other                   85\n",
      "New_Visitor           1694\n",
      "Returning_Visitor    10551\n",
      "Name: VisitorType, dtype: int64\n",
      "\n",
      "\n",
      "True     2868\n",
      "False    9462\n",
      "Name: Weekend, dtype: int64\n",
      "\n",
      "\n",
      "True      1908\n",
      "False    10422\n",
      "Name: Revenue, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Administrative'].value_counts(dropna=False, ascending=True))\n",
    "print('\\n')\n",
    "print(df['Administrative_Duration'].value_counts(dropna=False, ascending=True, bins = 8))\n",
    "print('\\n')\n",
    "print(df['Informational'].value_counts(dropna=False, ascending=False))\n",
    "print('\\n')\n",
    "print(df['Informational_Duration'].value_counts(dropna=False, ascending=True, bins = 8))\n",
    "print('\\n')\n",
    "print(df['ProductRelated'].value_counts(dropna=False))\n",
    "print('\\n')\n",
    "print(df['ProductRelated_Duration'].value_counts(dropna=False, ascending=True, bins = 8))\n",
    "print('\\n')\n",
    "print(df['BounceRates'].value_counts(dropna=False, ascending=True, bins = 8))\n",
    "print('\\n')\n",
    "print(df['ExitRates'].value_counts(dropna=False, ascending=True, bins = 8))\n",
    "print('\\n')\n",
    "print(df['PageValues'].value_counts(dropna=False, ascending=True, bins = 6))\n",
    "print('\\n')\n",
    "print(df['SpecialDay'].value_counts(dropna=False, ascending=True))\n",
    "print('\\n')\n",
    "print(df['OperatingSystems'].value_counts(dropna=False, ascending=True))\n",
    "print('\\n')\n",
    "print(df['Browser'].value_counts(dropna=False, ascending=True))\n",
    "print('\\n')\n",
    "print(df['Region'].value_counts(dropna=False, ascending=True))\n",
    "print('\\n')\n",
    "print(df['TrafficType'].value_counts(dropna=False, ascending=True))\n",
    "print('\\n')\n",
    "print(df['Month'].value_counts(dropna=False, ascending=True))\n",
    "print('\\n')\n",
    "print(df['VisitorType'].value_counts(dropna=False, ascending=True))\n",
    "print('\\n')\n",
    "print(df['Weekend'].value_counts(dropna=False, ascending=True))\n",
    "print('\\n')\n",
    "print(df['Revenue'].value_counts(dropna=False, ascending=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Administrative               0\n",
      "Administrative_Duration      0\n",
      "Informational                0\n",
      "Informational_Duration       0\n",
      "ProductRelated             335\n",
      "ProductRelated_Duration      0\n",
      "BounceRates                  0\n",
      "ExitRates                    0\n",
      "PageValues                   0\n",
      "SpecialDay                   0\n",
      "Month                        0\n",
      "OperatingSystems             0\n",
      "Browser                      0\n",
      "Region                       0\n",
      "TrafficType                  0\n",
      "VisitorType                  0\n",
      "Weekend                      0\n",
      "Revenue                      0\n",
      "dtype: int64\n",
      "Pct Missing from ProductRelated = 2.72%\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())\n",
    "missing = df['ProductRelated'].isna().sum()\n",
    "net = df['ProductRelated'].shape[0]\n",
    "pct = 100 * missing / net\n",
    "print(f'Pct Missing from ProductRelated = {round(pct, 2)}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Only the feature *ProductRelated* has missing data.  2.7% of the values are missing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Use the describe() method in pandas to print out summary statistics. Discuss which features you will have to consider more carefully, based on these results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Administrative  Administrative_Duration  Informational  \\\n",
      "count    12330.000000             12330.000000   12330.000000   \n",
      "mean         2.315166                80.818611       0.503569   \n",
      "std          3.321784               176.779107       1.270156   \n",
      "min          0.000000                 0.000000       0.000000   \n",
      "25%          0.000000                 0.000000       0.000000   \n",
      "50%          1.000000                 7.500000       0.000000   \n",
      "75%          4.000000                93.256250       0.000000   \n",
      "max         27.000000              3398.750000      24.000000   \n",
      "\n",
      "       Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
      "count            12330.000000    11995.000000             12330.000000   \n",
      "mean                34.472398       32.122134              1194.746220   \n",
      "std                140.749294       44.898778              1913.669288   \n",
      "min                  0.000000        0.000000                 0.000000   \n",
      "25%                  0.000000        7.000000               184.137500   \n",
      "50%                  0.000000       18.000000               598.936905   \n",
      "75%                  0.000000       38.000000              1464.157214   \n",
      "max               2549.375000      705.000000             63973.522230   \n",
      "\n",
      "        BounceRates     ExitRates    PageValues    SpecialDay  \\\n",
      "count  12330.000000  12330.000000  12330.000000  12330.000000   \n",
      "mean       0.022191      0.043073      5.889258      0.061427   \n",
      "std        0.048488      0.048597     18.568437      0.198917   \n",
      "min        0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.014286      0.000000      0.000000   \n",
      "50%        0.003112      0.025156      0.000000      0.000000   \n",
      "75%        0.016813      0.050000      0.000000      0.000000   \n",
      "max        0.200000      0.200000    361.763742      1.000000   \n",
      "\n",
      "       OperatingSystems       Browser        Region   TrafficType  \n",
      "count      12330.000000  12330.000000  12330.000000  12330.000000  \n",
      "mean           2.124006      2.357097      3.147364      4.069586  \n",
      "std            0.911325      1.717277      2.401591      4.025169  \n",
      "min            1.000000      1.000000      1.000000      1.000000  \n",
      "25%            2.000000      2.000000      1.000000      2.000000  \n",
      "50%            2.000000      2.000000      3.000000      2.000000  \n",
      "75%            3.000000      2.000000      4.000000      4.000000  \n",
      "max            8.000000     13.000000      9.000000     20.000000  \n",
      " \n",
      "Administrative - 8.13\n",
      "Administrative_Duration - 19.23\n",
      "Informational - 18.9\n",
      "Informational_Duration - 18.11\n",
      "ProductRelated - 15.7\n",
      "ProductRelated_Duration - 33.43\n",
      "BounceRates - 4.12\n",
      "ExitRates - 4.12\n",
      "PageValues - 19.48\n",
      "SpecialDay - 5.03\n",
      "OperatingSystems - 7.68\n",
      "Browser - 6.99\n",
      "Region - 3.33\n",
      "TrafficType - 4.72\n"
     ]
    }
   ],
   "source": [
    "des = df.describe()\n",
    "print(des)\n",
    "print(' ')\n",
    "\n",
    "# one indicator of 'a field to keep an eye on' is how many std devs separate the min from the max\n",
    "for column in des:\n",
    "    r = des[column]['max'] - des[column]['min']\n",
    "    num_devs = r / des[column]['std']\n",
    "    print(f'{des[column].name} - {round(num_devs, 2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on these results, there are a couple fields I will consider more carefully.  At first glance, the *_Duration* fields appear to have much higher means and much greater variation.  These may be candidates for scaling/normalization.\n",
    "<br>\n",
    "To get a better sense of the data I took a look at the number of standard deviations that comprise the range for each series.  This quick analysis showed that *PageValues*, *Informational*, and *ProductRelated* also have a bit of variation that may need to be dealt with."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Handle any missing data in your training data, but do not simply delete the rows. In your notebook, discuss why you chose to handle the missing data that way.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### The holdout dataset also contains missing data. Discuss and implement how you recovered those items, without deleting those rows.\n",
    "*In this instance, the holdout data does not include any missing data.  If it did, I would've handled it the same way I handled the missing data in the training set.*\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Discuss (and implement if applicable) whether or not you need to scale/normalize your features, and which ones, if any."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### There are several categorical features. Discuss and implement if you will encode them as ordinal numbers, or one-hot encode them, and why you chose to do so for each such feature."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### You don't need to implement this, but in the dataset, were there any ordinal features that they authors should have recorded as categorical, in your opinion? Why or why not? Discuss in a markdown cell."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 3: Feature Simplification And Engineering\n",
    "##### Use a heatmap to show the correlation between all feature pairs. Discuss, if any, which features you would recommend dropping from your model. Also discuss why you would want to drop them (what is the expected benefit?)\t5 points"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Given what you know about the limitations of RandomForests, engineer one additional feature, and discuss why you think it might help the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 4: Model Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Separate your training data into features and labels (X and y)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### The labels for this dataset are highly imbalanced. Discuss and implement how you will handle this situation for this analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Instantiate a RandomForest model of your choosing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Define a grid to tune at least three different hyperparameters with at least two different values each. Discuss why you think these parameter values might be useful for this dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Set up a gridsearchCV with 5-fold cross validation. Discuss what accuracy metric you chose and why."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Train your model using gridsearchCV, and report the best performing hyperparameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 5: Model Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Calculate accuracy, precision and recall on the holdout dataset. Discuss which metric you think is most meaningful for this dataset, and why"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Discuss how the model performance on holdout compares to the model performance during training. Do you think your model will generalize well? Why or why not?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Generate a confusion matrix and discuss your results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Print out the feature importances of your model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 6: Model Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Train and tune another decision-tree based model on your training dataset. Using the best performing hyperparameters, test this model on your holdout. How did it perform, compared to your earlier model? Do you think your results will generalize?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Next, repeat training and tuning on the same data with a LogisticRegression model. Do you need to do any additional feature cleaning or scaling here? Why or why not?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extra Credit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}