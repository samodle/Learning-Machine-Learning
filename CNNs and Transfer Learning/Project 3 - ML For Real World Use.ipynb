{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Sam Odle <br>\n",
    "December 2021  <br>\n",
    "Project 3  <br>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Whether to train on a gpu\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "print(f'Train on gpu: {train_on_gpu}')\n",
    "\n",
    "# Number of gpus\n",
    "if train_on_gpu:\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f'{gpu_count} gpus detected.')\n",
    "    if gpu_count > 1:\n",
    "        multi_gpu = True\n",
    "    else:\n",
    "        multi_gpu = False\n",
    "\n",
    "CUDA_DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(CUDA_DEVICE)\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 1: Generating Test Cases\n",
    "###### In this section, we're going to design some datasets to convince ourselves that our model is giving us reasonable results. First, we'll generate some toy datasets from the Stanford dogs dataset where we know what the correct outcome should be. Complete the items below:\n",
    "\n",
    "###### Generate a dataset of just three images, one for each class, and show your model correctly labels them. (display each image in your notebook, pass it to your model, and then print the prediction).\t5 points"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Generate three datasets of our inputs, where each has only two of the classes. What do you predict the performance should be for three binary classifiers trained on these three datasets? Re-train your model on these three datasets, and discuss your results.\t5 points"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Generate a dataset from your original dataset where 20% of the classes in one class are mis-labelled as the remaining two classes. How do you think your model performance will be impacted? Re-train your model on this test dataset, and discuss your results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 2: Biases in the modeling\n",
    "\n",
    "###### Take a look at each of the images in all classes individually. What aspects of the image (such as backgrounds) might be influencing the decision-making of the model, besides the dogs themselves?\t5 points\n",
    "###### Calculate the \"average image\" across all pixels of each of your classes in your training dataset. Are your results consistent with the previous item?\t5 points\n",
    "###### Is the data biased in any way that could impact your results? Why or why not?\n",
    "###### If you noted some potential biases in the modeling/dataset above, discuss how you could help mitigate these biases (you don't need to implement, just discuss). If you didn't note any biases in this dataset, discuss what biases there could have been, and how the dataset designers might have helped mitigate them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Part 3: Model uncertainty and explainability\n",
    "We discussed earlier this semester how deep learning models can be black boxes; it's hard to tell what the models really learned, that is, what are the using to make their decisions?\n",
    "\n",
    "Overall, we got incredibly good performance earlier with just a couple hundred images per class. Let's investigate how much pre-training with ImageNet helped us achieve those results. First, re-train your model, but this time don't use a pre-trained version (you can set the flag to False). What happened? Include a discussion in your notebook.\n",
    "\n",
    "Next, let's see what happens in two cases:\n",
    "When we try to build a model on just the head of the dog (cropping just the head/face)\n",
    "When we crop the dog out of the image, leaving just the background\n",
    "Discuss two hypotheses for the two datasets above -- how do you think they should perform, and why. If you have time, you can manually build the two datasets above and re-train your model, but you're not required to.\n",
    "\n",
    "Pixel importance with saliency maps\n",
    "Finally, let's see how much each pixel contributes to the final decision of the model using saliency mapping. Although saliency mapping has its limitations and is not the be-all-end-all of this type of analysis, it will at least get us started this semester towards a discussion of model explainability.\n",
    "\n",
    "Write a loop that goes through every image in your dataset and prints out the original image and a saliency map for each image. Use any resources you find online (other than asking someone to do the work for you!) to generate such a saliency map; you can probably do this in about 20 lines of code without the need to import any more libraries, but feel free to get fancy! If you get stuck, as us for help on Ed. Make sure you cite any resources you used!\n",
    "\n",
    "Finally, include a discussion of the output of your saliency analysis for this dataset -- what do you think this means in terms of your model performance?\n",
    "\n",
    "\n",
    "###### Discussion of how model should behave if trained just on heads of dogs\n",
    "###### Discussion of how model should behave if trained just on backgrounds without dogs\n",
    "###### Discussion of model performance without using pre-trained weights vs using pre-trained weights.\n",
    "###### Correctly implementing saliency maps for all images.\t5 points\n",
    "###### Discussion of saliency mapping results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import random\n",
    "\n",
    "directory = '/Users/samodle/Documents/Repos/SimpleMachineLearningProjects/CNNs and Transfer Learning/Images/'\n",
    "\n",
    "num_training_images_per_breed = 100\n",
    "num_test_images_per_breed = 25\n",
    "source_paths = ['n02109047-Great_Dane', 'n02094258-Norwich_terrier', 'n02094114-Norfolk_terrier']\n",
    "destination_paths = ['train/', 'test/', 'holdout/']\n",
    "\n",
    "dest_train = 0\n",
    "dest_test = 1\n",
    "dest_holdout = 2\n",
    "\n",
    "for path in destination_paths:\n",
    "    if not os.path.exists(directory + path):\n",
    "      # Create a new directory because it does not exist\n",
    "      os.makedirs(directory + path)\n",
    "      print(f'Directory Created: {path}')\n",
    "    else:\n",
    "        print(f'Already Exists: {path}')\n",
    "\n",
    "    if not os.path.exists(directory + path + 'great_dane/'):\n",
    "        os.makedirs(directory + path + 'great_dane/')\n",
    "        print(f'Directory Created: {path}')\n",
    "\n",
    "    if not os.path.exists(directory + path + 'norwich_terrier/'):\n",
    "        os.makedirs(directory + path + 'norwich_terrier/')\n",
    "\n",
    "    if not os.path.exists(directory + path + 'norfolk_terrier/'):\n",
    "        os.makedirs(directory + path + 'norfolk_terrier/')\n",
    "        print(f'Directory Created: {path}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# split up the training, holdout, and test datasets\n",
    "for path in source_paths:\n",
    "    all_files = os.listdir(directory + path)\n",
    "\n",
    "    #split out the training data\n",
    "    train = random.sample(all_files, num_training_images_per_breed)\n",
    "\n",
    "    if 'Great_Dane' in path:\n",
    "        for f in train:\n",
    "            shutil.copy(directory + path + '/' + f, directory + destination_paths[dest_train] + 'great_dane/')\n",
    "    elif 'Norwich' in path:\n",
    "         for f in train:\n",
    "            shutil.copy(directory + path + '/' + f, directory + destination_paths[dest_train] + 'norwich_terrier/')\n",
    "    elif 'Norfolk' in path:\n",
    "        for f in train:\n",
    "            shutil.copy(directory + path + '/' + f, directory + destination_paths[dest_train] + 'norfolk_terrier/')\n",
    "\n",
    "\n",
    "    test_and_hold = [x for x in all_files if x not in train]\n",
    "    # print(train)\n",
    "\n",
    "    #split the test from the holdout\n",
    "    test = random.sample(test_and_hold, num_test_images_per_breed)\n",
    "\n",
    "    if 'Great_Dane' in path:\n",
    "        for f in test:\n",
    "            shutil.copy(directory + path + '/' + f, directory + destination_paths[dest_test] + 'great_dane/')\n",
    "    elif 'Norwich' in path:\n",
    "         for f in test:\n",
    "            shutil.copy(directory + path + '/' + f, directory + destination_paths[dest_test] + 'norwich_terrier/')\n",
    "    elif 'Norfolk' in path:\n",
    "        for f in test:\n",
    "            shutil.copy(directory + path + '/' + f, directory + destination_paths[dest_test] + 'norfolk_terrier/')\n",
    "\n",
    "\n",
    "    holdout = [x for x in test_and_hold if x not in test]\n",
    "    if 'Great_Dane' in path:\n",
    "        for f in holdout:\n",
    "            shutil.copy(directory + path + '/' + f, directory + destination_paths[dest_holdout] + 'great_dane/')\n",
    "    elif 'Norwich' in path:\n",
    "         for f in holdout:\n",
    "            shutil.copy(directory + path + '/' + f, directory + destination_paths[dest_holdout] + 'norwich_terrier/')\n",
    "    elif 'Norfolk' in path:\n",
    "        for f in holdout:\n",
    "            shutil.copy(directory + path + '/' + f, directory + destination_paths[dest_holdout] + 'norfolk_terrier/')\n",
    "\n",
    "    print(test)\n",
    "    print(holdout)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=[224,224]),\n",
    "    transforms.RandomRotation(degrees=90),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([\n",
    "        transforms.Resize(size=[224,224]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "        transforms.Resize(size=[224,224]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "WORKERS = 4\n",
    "DROP = False\n",
    "\n",
    "TRAIN_DATA_PATH = \"./images/train/\"\n",
    "TEST_DATA_PATH = \"./images/test/\"\n",
    "HOLDOUT_DATA_PATH = \"./images/holdout/\"\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=train_transforms)\n",
    "train_data_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True,  num_workers=WORKERS, drop_last=DROP)\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, transform=test_transforms)\n",
    "test_data_loader  = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS, drop_last=DROP)\n",
    "\n",
    "holdout_data = torchvision.datasets.ImageFolder(root=HOLDOUT_DATA_PATH, transform=test_transforms)\n",
    "holdout_data_loader  = data.DataLoader(holdout_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS, drop_last=DROP)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = train_data.classes\n",
    "print(class_names)\n",
    "\n",
    "#source: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(train_data_loader))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "model = torchvision.models.vgg19(pretrained=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "\n",
    "# Freeze early layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "n_inputs = model.classifier[6].in_features\n",
    "\n",
    "# Add on classifier\n",
    "# modified from: https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce\n",
    "model.classifier[6] = nn.Sequential(\n",
    "                      nn.Linear(n_inputs, 256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(256, n_classes),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "print(model.classifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Move to gpu and parallelize\n",
    "if train_on_gpu:\n",
    "    model = model.to('cuda')\n",
    "\n",
    "if multi_gpu:\n",
    "    model = nn.DataParallel(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          train_loader,\n",
    "          valid_loader,\n",
    "          save_file_name,\n",
    "          max_epochs_stop=3,\n",
    "          n_epochs=20,\n",
    "          print_every=1):\n",
    "    \"\"\"Train a PyTorch Model\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        model (PyTorch model): cnn to train\n",
    "        criterion (PyTorch loss): objective to minimize\n",
    "        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n",
    "        train_loader (PyTorch dataloader): training dataloader to iterate through\n",
    "        valid_loader (PyTorch dataloader): validation dataloader used for early stopping\n",
    "        save_file_name (str ending in '.pt'): file path to save the model state dict\n",
    "        max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\n",
    "        n_epochs (int): maximum number of training epochs\n",
    "        print_every (int): frequency of epochs to print training stats\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        model (PyTorch model): trained cnn with best weights\n",
    "        history (DataFrame): history of train and validation loss and accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Early stopping intialization\n",
    "    epochs_no_improve = 0\n",
    "    valid_loss_min = np.Inf\n",
    "\n",
    "    valid_max_acc = 0\n",
    "    history = []\n",
    "\n",
    "    # Number of epochs already trained (if using loaded in model weights)\n",
    "    try:\n",
    "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
    "    except:\n",
    "        model.epochs = 0\n",
    "        print(f'Starting Training from Scratch.\\n')\n",
    "\n",
    "    overall_start = timer()\n",
    "\n",
    "    # Main loop\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # keep track of training and validation loss each epoch\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_acc = 0\n",
    "        valid_acc = 0\n",
    "\n",
    "        # Set to training\n",
    "        model.train()\n",
    "        start = timer()\n",
    "\n",
    "        # Training loop\n",
    "        for ii, (data, target) in enumerate(train_loader):\n",
    "            # Tensors to gpu\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Predicted outputs are log probabilities\n",
    "            output = model(data)\n",
    "\n",
    "            # Loss and backpropagation of gradients\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track train loss by multiplying average loss by number of examples in batch\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "\n",
    "            # Calculate accuracy by finding max log probability\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "            # Need to convert correct tensor from int to float to average\n",
    "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "            # Multiply average accuracy times the number of examples in batch\n",
    "            train_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "            # Track training progress\n",
    "            print(\n",
    "                f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
    "                end='\\r')\n",
    "\n",
    "        # After training loops ends, start validation\n",
    "        else:\n",
    "            model.epochs += 1\n",
    "\n",
    "            # Don't need to keep track of gradients\n",
    "            with torch.no_grad():\n",
    "                # Set to evaluation mode\n",
    "                model.eval()\n",
    "\n",
    "                # Validation loop\n",
    "                for data, target in valid_loader:\n",
    "                    # Tensors to gpu\n",
    "                    if train_on_gpu:\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                    # Forward pass\n",
    "                    output = model(data)\n",
    "\n",
    "                    # Validation loss\n",
    "                    loss = criterion(output, target)\n",
    "                    # Multiply average loss times the number of examples in batch\n",
    "                    valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                    # Calculate validation accuracy\n",
    "                    _, pred = torch.max(output, dim=1)\n",
    "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "                    accuracy = torch.mean(\n",
    "                        correct_tensor.type(torch.FloatTensor))\n",
    "                    # Multiply average accuracy times the number of examples\n",
    "                    valid_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "                # Calculate average losses\n",
    "                train_loss = train_loss / len(train_loader.dataset)\n",
    "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "\n",
    "                # Calculate average accuracy\n",
    "                train_acc = train_acc / len(train_loader.dataset)\n",
    "                valid_acc = valid_acc / len(valid_loader.dataset)\n",
    "\n",
    "                history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
    "\n",
    "                # Print training and validation results\n",
    "                if (epoch + 1) % print_every == 0:\n",
    "                    print(\n",
    "                        f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
    "                    )\n",
    "                    print(\n",
    "                        f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
    "                    )\n",
    "\n",
    "                # Save the model if validation loss decreases\n",
    "                if valid_loss < valid_loss_min:\n",
    "                    # Save model\n",
    "                    torch.save(model.state_dict(), save_file_name)\n",
    "                    # Track improvement\n",
    "                    epochs_no_improve = 0\n",
    "                    valid_loss_min = valid_loss\n",
    "                    valid_best_acc = valid_acc\n",
    "                    best_epoch = epoch\n",
    "\n",
    "                # Otherwise increment count of epochs with no improvement\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    # Trigger early stopping\n",
    "                    if epochs_no_improve >= max_epochs_stop:\n",
    "                        print(\n",
    "                            f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "                        )\n",
    "                        total_time = timer() - overall_start\n",
    "                        print(\n",
    "                            f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
    "                        )\n",
    "\n",
    "                        # Load the best state dict\n",
    "                        model.load_state_dict(torch.load(save_file_name))\n",
    "                        # Attach the optimizer\n",
    "                        model.optimizer = optimizer\n",
    "\n",
    "                        # Format history\n",
    "                        history = pd.DataFrame(\n",
    "                            history,\n",
    "                            columns=[\n",
    "                                'train_loss', 'valid_loss', 'train_acc',\n",
    "                                'valid_acc'\n",
    "                            ])\n",
    "                        return model, history\n",
    "\n",
    "    # Attach the optimizer\n",
    "    model.optimizer = optimizer\n",
    "    # Record overall time and print out stats\n",
    "    total_time = timer() - overall_start\n",
    "    print(\n",
    "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "    )\n",
    "    print(\n",
    "        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n",
    "    )\n",
    "    # Format history\n",
    "    history = pd.DataFrame(\n",
    "        history,\n",
    "        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
    "    return model, history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model, history = train(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_data_loader,\n",
    "    test_data_loader,\n",
    "    save_file_name='dog_id_model',\n",
    "    max_epochs_stop=20,\n",
    "    n_epochs=45,\n",
    "    print_every=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_loss', 'valid_loss']:\n",
    "    plt.plot(\n",
    "        history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Negative Log Likelihood')\n",
    "plt.title('Training and Validation Losses')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_acc', 'valid_acc']:\n",
    "    plt.plot(\n",
    "        100 * history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "holdout_loss = 0.0\n",
    "holdout_acc = 0\n",
    "\n",
    "#test_loader.dataset.t\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Validation loop\n",
    "    for data, target in holdout_data_loader:\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "\n",
    "        # Validation loss\n",
    "        loss = criterion(output, target)\n",
    "        # Multiply average loss times the number of examples in batch\n",
    "        holdout_loss += loss.item() * data.size(0)\n",
    "\n",
    "        # Calculate validation accuracy\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "        correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "        accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "        # Multiply average accuracy times the number of examples\n",
    "        holdout_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "    # Calculate average losses\n",
    "    holdout_loss = holdout_loss / len(holdout_data_loader.dataset)\n",
    "\n",
    "    # Calculate average accuracy\n",
    "    holdout_acc = holdout_acc / len(holdout_data_loader.dataset)\n",
    "    holdout_acc = round(holdout_acc*100, 2)\n",
    "\n",
    "print(f'Holdout Accuracy: {holdout_acc}%')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extra Credit"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}